{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0qvXCR/WrDFoEs8qLEgYs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajagopalmotivate/WiproMultiModalClassifierOffensive/blob/main/Enduser_Declares_Active_Features_to_improve_X_Multimodal_classifer_ver_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step Pre 0: Install stuff that require restart of runtime "
      ],
      "metadata": {
        "id": "g6uLK0vj8roI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "85LZgIZ-iXsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "\n",
        "!sudo apt install tesseract-ocr\n"
      ],
      "metadata": {
        "id": "0Xn4HKaq8p0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install libtesseract-dev"
      ],
      "metadata": {
        "id": "ACdzGlnE9xwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "vIKFoyjuS4xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Download the dataset  \n",
        "download the images and 3 CSV file"
      ],
      "metadata": {
        "id": "y9ZD5LaHHLCE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD5NRsMFIZbO"
      },
      "outputs": [],
      "source": [
        "#images\n",
        "#https://drive.google.com/drive/folders/1GGy63-KlrSLjhpbTNGV-ObS_M4JMxeLr?usp=share_link\n",
        "#https://drive.google.com/drive/folders/1hKLOtpVmF45IoBmJPwojgq6XraLtHmV6\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CSV \n",
        "#https://drive.google.com/drive/folders/1ckOGoRmMwCEFo-k3UX7J2lnzg495WIS5?usp=share_link\n"
      ],
      "metadata": {
        "id": "GYxMCwh3KHs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = 'nandriImages/'\n",
        "try:\n",
        "    os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "local_download_path = 'nandriCSV/'\n",
        "try:\n",
        "    os.makedirs(local_download_path)\n",
        "except: pass\n"
      ],
      "metadata": {
        "id": "QtH_a-_SKfjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "PHloSJNENs91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "\n",
        " \n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1ckOGoRmMwCEFo-k3UX7J2lnzg495WIS5' in parents\"}).GetList()  #use your own folder ID here\n",
        "\n",
        "for f in file_list:\n",
        "    # 3. Create & download by id.\n",
        "    print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "    fname = f['title']\n",
        "    print('downloading to {}'.format(fname))\n",
        "    f_ = drive.CreateFile({'id': f['id']})\n",
        "    f_.GetContentFile(fname)"
      ],
      "metadata": {
        "id": "v6z3LBS7HD4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5-P_lf-hlJpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "\n",
        " \n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1GGy63-KlrSLjhpbTNGV-ObS_M4JMxeLr' in parents\"}).GetList()  #use your own folder ID here\n",
        "\n",
        "if False:\n",
        "  for f in file_list:\n",
        "    # 3. Create & download by id.\n",
        "    print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "    fname = f['title']\n",
        "    print('downloading to {}'.format(fname))\n",
        "    f_ = drive.CreateFile({'id': f['id']})\n",
        "    f_.GetContentFile(fname)"
      ],
      "metadata": {
        "id": "IIE1CDK9G_WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://drive.google.com/drive/folders/1qvWrxquhgW55O17sPfXGQ8Er4LB0oqxp?usp=share_link\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1qvWrxquhgW55O17sPfXGQ8Er4LB0oqxp' in parents\"}).GetList()  #use your own folder ID here\n",
        "\n",
        "for f in file_list:\n",
        "    # 3. Create & download by id.\n",
        "    print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "    fname = f['title']\n",
        "    print('downloading to {}'.format(fname))\n",
        "    f_ = drive.CreateFile({'id': f['id']})\n",
        "    f_.GetContentFile(fname)"
      ],
      "metadata": {
        "id": "z_3BSCeokPDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"Labelled Images-20221211T030207Z-001.zip\""
      ],
      "metadata": {
        "id": "RSpcyeOhkggC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"Labelled Images-20221211T030207Z-001.zip\", 'r')\n",
        "zip_ref.extractall(\"nandri/\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "z1S3FwWdk0YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/nandri/Labelled Images"
      ],
      "metadata": {
        "id": "ZJq-Pjrwmmpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Understand the problem statement /  Explore dataset"
      ],
      "metadata": {
        "id": "BFHfWSlOLowM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1a: Understand the problem statment "
      ],
      "metadata": {
        "id": "VaXnqoc5LsVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        " "
      ],
      "metadata": {
        "id": "WJfEoK_CMCm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Domain expert declares the features to be explored"
      ],
      "metadata": {
        "id": "x8E26Rz-v_5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.A: What could be the features to look for ? Just jot it down. And the AI will auto consider those as part of ZERO SHOT CLASSIFER to teach the AI about features!   \n",
        "\n",
        "This is UI for Wipro Domain Experts. Just type here!\n",
        "\n",
        "E.g. (HLS domain consultants - can suggest features to look out for such as 'hairline fracture', 'nuemonia' .  )"
      ],
      "metadata": {
        "id": "2AdBKSwKwHi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "What_could_be_classes_ZEROSHOT = \"offensive, non offensive, racist, non-racist\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "OdWwVeVgvxml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ZEROSHOTcandidate_labels = What_could_be_classes_ZEROSHOT.split(\",\")\n",
        "for i in range(len(ZEROSHOTcandidate_labels)):\n",
        "  ZEROSHOTcandidate_labels[i] = ZEROSHOTcandidate_labels[i].strip()\n",
        "\n",
        "\n",
        "ZEROSHOTcandidate_labels"
      ],
      "metadata": {
        "id": "Yz2jRZqVy0Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "What_could_be_VISUALREASONING_Factors = \"offensive, non offensive,  extremely offensive,  nudity or sexual, violence\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "-1JRX9QvOISK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "What_could_be_VISUALREASONING_Factors2 = \"abuse of women, violence against women, black people as slaves, man attacking women, racist behavior\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "80D5lhKIY3zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "What_could_be_supplemental_VISUALREASONING_Factors = \"is a clipart, is filled with text\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "B9e2nJIeVIqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VISUALREASONING_Factors = What_could_be_VISUALREASONING_Factors.split(\",\")\n",
        "for i in range(len(VISUALREASONING_Factors)):\n",
        "  VISUALREASONING_Factors[i] = VISUALREASONING_Factors[i].strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZSyIIq_WVelD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VISUALREASONING_Factors2 = What_could_be_VISUALREASONING_Factors2.split(\",\")\n",
        "for i in range(len(VISUALREASONING_Factors2)):\n",
        "  VISUALREASONING_Factors2[i] = VISUALREASONING_Factors2[i].strip()"
      ],
      "metadata": {
        "id": "KS7IflIeWn0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VISUALREASONING_Factors3 = What_could_be_supplemental_VISUALREASONING_Factors.split(\",\")\n",
        "for i in range(len(VISUALREASONING_Factors3)):\n",
        "  VISUALREASONING_Factors3[i] = VISUALREASONING_Factors3[i].strip()"
      ],
      "metadata": {
        "id": "O3EDucH8Z4vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(VISUALREASONING_Factors)):\n",
        "  print ( \"This image contains \" + VISUALREASONING_Factors[i] + \" content\")\n",
        "for i in range(len(VISUALREASONING_Factors2)):\n",
        "  print(\"This image shows \" + VISUALREASONING_Factors2[i])\n",
        "for i in range(len(VISUALREASONING_Factors3)):\n",
        "  print(\"This image \" + VISUALREASONING_Factors3[i]) "
      ],
      "metadata": {
        "id": "v3_YlNfLWwcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VISUALREASONING_FactorsALL_ColomnName = []\n",
        "VISUALREASONING_FactorsALL_Reasoning = []\n",
        "\n",
        "for i in range(len(VISUALREASONING_Factors)):\n",
        "  VISUALREASONING_FactorsALL_ColomnName.append( \"NLVR.\"+VISUALREASONING_Factors[i])\n",
        "  VISUALREASONING_FactorsALL_Reasoning.append(\"This image contains \" + VISUALREASONING_Factors[i] + \" content\")\n",
        "for i in range(len(VISUALREASONING_Factors2)):\n",
        "  VISUALREASONING_FactorsALL_ColomnName.append(\"NLVR.\"+VISUALREASONING_Factors2[i])\n",
        "  VISUALREASONING_FactorsALL_Reasoning.append(\"This image shows \" + VISUALREASONING_Factors2[i])\n",
        "for i in range(len(VISUALREASONING_Factors3)):\n",
        "  VISUALREASONING_FactorsALL_ColomnName.append(\"NLVR.\"+VISUALREASONING_Factors3[i])\n",
        "  VISUALREASONING_FactorsALL_Reasoning.append(\"This image \" + VISUALREASONING_Factors3[i])\n",
        "\n"
      ],
      "metadata": {
        "id": "YjTvkizHb5Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(len (VISUALREASONING_FactorsALL_ColomnName)):\n",
        "  print( str(i) + \". \" + VISUALREASONING_FactorsALL_ColomnName[i] + \"   ---------------------      \"   + VISUALREASONING_FactorsALL_Reasoning[i])"
      ],
      "metadata": {
        "id": "0-3pM3ZCcxr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Extract features \n"
      ],
      "metadata": {
        "id": "xGvOUpFIIzHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw_Test = pd.read_csv(\"/content/Testing_meme_dataset.csv\")\n",
        "dfraw_Test[\"DATASET\"] = \"TEST\"\n",
        "dfraw_Train = pd.read_csv(\"/content/Training_meme_dataset.csv\")\n",
        "dfraw_Train[\"DATASET\"] = \"TRAIN\"\n",
        "dfraw_Val = pd.read_csv(\"/content/Validation_meme_dataset.csv\")\n",
        "dfraw_Val[\"DATASET\"] = \"VAL\"\n",
        "\n",
        "dfraw = dfraw_Train.append(dfraw_Val, ignore_index=True) \n",
        "dfraw = dfraw.append(dfraw_Test, ignore_index=True )"
      ],
      "metadata": {
        "id": "2KCDuq8aI613"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw = dfraw[0:6]"
      ],
      "metadata": {
        "id": "4AlsE-7kfB_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw"
      ],
      "metadata": {
        "id": "iaC59S6HfZWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "image1 = Image.open( dfraw['image_name'][2])\n",
        "display(image1)\n",
        " "
      ],
      "metadata": {
        "id": "ZADFeHJWNcf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2a. Extract image features and add to dataset \n",
        " Apply \"Declarative Feature extraction\" from Visual Language Foundation models such as CLIP, VLIT, etc \n",
        " We can extract features "
      ],
      "metadata": {
        "id": "rfzuClzdI7DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import pytesseract\n",
        "\n"
      ],
      "metadata": {
        "id": "zDshMzLSEF4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countofRecordstoProcess  = len(dfraw )\n"
      ],
      "metadata": {
        "id": "V_a3qW-FYr6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OCR_tesseract_config = r'--psm 1'\n",
        "\n",
        "if False:\n",
        "  for i in range( countofRecordstoProcess ):  \n",
        "    img = cv2.imread(dfraw['image_name'][i] )\n",
        "    ocrtext = pytesseract.image_to_string(img, config=OCR_tesseract_config) \n",
        "    dfraw.at[i , \"OCR\" ] =  ocrtext"
      ],
      "metadata": {
        "id": "-7dZktzIF15v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "Q5b2utPWGWpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ETw4MmiaincB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "59TYjde-ImDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViltProcessor, ViltForImagesAndTextClassification\n",
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-nlvr2\")\n",
        "model = ViltForImagesAndTextClassification.from_pretrained(\"dandelin/vilt-b32-finetuned-nlvr2\")\n"
      ],
      "metadata": {
        "id": "OR4ZoeWmLEQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def understnadImage(image1 , text):\n",
        "  encoding = processor([image1, image1], text, return_tensors=\"pt\")\n",
        "  # forward pass\n",
        "  outputs = model(input_ids=encoding.input_ids, pixel_values=encoding.pixel_values.unsqueeze(0))\n",
        "  logits = outputs.logits\n",
        "  idx = logits.argmax(-1).item()\n",
        "  #print(\"Predicted answer:\", model.config.id2label[idx]),\n",
        "  return idx"
      ],
      "metadata": {
        "id": "zBXX-MzYa7Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n"
      ],
      "metadata": {
        "id": "uwCD6N7NJMAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def understnadImage1(image1 , text):\n",
        "  encoding = processor([image1, image1], text, return_tensors=\"pt\")\n",
        "  # forward pass\n",
        "  outputs = model(input_ids=encoding.input_ids, pixel_values=encoding.pixel_values.unsqueeze(0))\n",
        "  logits = outputs.logits\n",
        "  idx = logits.argmax(-1).item()\n",
        "  #print(\"Predicted answer:\", model.config.id2label[idx])\n",
        "  scores = outputs[0][0].detach().numpy()\n",
        "  scores = softmax(scores)  \n",
        "  return idx, round ( scores[0] , 1)  , round ( scores[1] , 1) "
      ],
      "metadata": {
        "id": "s-Fczmi4Ipe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = Image.open( dfraw['image_name'][1]  )\n",
        "image1 = image1.convert('RGB')\n",
        "display(image1)\n",
        "\n",
        "understnadImage1(image1 , \"The image contains offensive content.\")"
      ],
      "metadata": {
        "id": "gLaYdfNcw9KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZRLy3qXFCd-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  for i in range( countofRecordstoProcess ):\n",
        "    image1 = Image.open( dfraw['image_name'][i]  )\n",
        "    image1 = image1.convert('RGB')\n",
        "    isclipart, isclipart0, isclipart1  = understnadImage1(image1, \"The image is a clipart.\")\n",
        "    dfraw.at[i , \"isclipart\" ] =  round( isclipart)\n",
        "    isobscene, isobscene0, isobscene1 = understnadImage1(image1, \"The image contains nudity or sexual content.\")\n",
        "    dfraw.at[i , \"isImageobscene\" ] =  round( isobscene)\n",
        "    isExteremeOffensive, isExteremeOffensive0, isExteremeOffensive1 = understnadImage1(image1, \"The image contains extremely offensive content.\")\n",
        "    dfraw.at[i , \"isImageExtremelyOffensive\" ] =  round( isExteremeOffensive)\n",
        "    isOffensive, isOffensive0, isOffensive1 = understnadImage1(image1, \"The image contains offensive content.\")\n",
        "    dfraw.at[i , \"isImageOffensive\" ] =  round( isOffensive)\n",
        "    dfraw.at[i , \"isclipart0\" ] =  round (isclipart0, 1)\n",
        "    dfraw.at[i , \"isclipart1\" ] =  round ( isclipart1, 1)\n",
        "    dfraw.at[i , \"isImageobscene0\" ] =  round ( isobscene0, 1)\n",
        "    dfraw.at[i , \"isImageobscene1\" ] =   round (isobscene1  , 1)\n",
        "    dfraw.at[i , \"isImageExtremelyOffensive0\" ] = round (isExteremeOffensive0, 1)\n",
        "    dfraw.at[i , \"isImageExtremelyOffensive1\" ] = round (isExteremeOffensive1, 1)\n",
        "    dfraw.at[i , \"isImageOffensive0\" ] =  round (isOffensive0, 1)\n",
        "    dfraw.at[i , \"isImageOffensive1\" ] =  round (isOffensive1, 1)\n",
        "\n",
        "  \n",
        " \n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "0ZnHcHRKbytH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizerHate = AutoTokenizer.from_pretrained(\"elozano/tweet_offensive_eval\")\n",
        "\n",
        "classifierHate = AutoModelForSequenceClassification.from_pretrained(\"elozano/tweet_offensive_eval\")"
      ],
      "metadata": {
        "id": "A7z2dX2hTPJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "3QU9SP7WV2j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def isOffensiveText(text1):\n",
        "  inputs = tokenizerHate(text1, return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "    logits = classifierHate(**inputs).logits\n",
        "  predicted_class_id = logits.argmax().item()\n",
        "  #print(model.config.id2label[predicted_class_id])\n",
        "  return predicted_class_id"
      ],
      "metadata": {
        "id": "ndp5E3XDWGJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def isOffensiveText1(text1):\n",
        "  inputs = tokenizerHate(text1, return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "    outputs = classifierHate(**inputs)\n",
        "    logits = outputs.logits\n",
        "  predicted_class_id = logits.argmax().item()\n",
        "  scores = outputs[0][0].detach().numpy()\n",
        "  scores = softmax(scores)    \n",
        "  #print(model.config.id2label[predicted_class_id])\n",
        "  return predicted_class_id, round ( scores[0] , 1)  , round ( scores[1] , 1) "
      ],
      "metadata": {
        "id": "ooWdvb8iA8Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range( countofRecordstoProcess ):  \n",
        "  text1 =  dfraw['sentence'][i] \n",
        "  text1 = str(text1)\n",
        "  isOffensiveTextans, isOffensiveTextans0, isOffensiveTextans1 = isOffensiveText1(text1)\n",
        "  dfraw.at[i , \"CAT.isOffensiveText1\" ] =   isOffensiveTextans  \n",
        "  dfraw.at[i , \"NUM.isOffensiveText1softm0\" ] =   round (isOffensiveTextans0, 1)\n",
        "  dfraw.at[i , \"NUM.isOffensiveText1softm1\" ] =   round (isOffensiveTextans1, 1)\n"
      ],
      "metadata": {
        "id": "6eV-3Ax1EUSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw"
      ],
      "metadata": {
        "id": "GPfbxrX1EuRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  for i in range( countofRecordstoProcess ):  \n",
        "    text1 =  dfraw['sentence'][i] \n",
        "    text1 = str(text1)\n",
        "    isOffensiveTextans, isOffensiveTextans0, isOffensiveTextans1 = isOffensiveText1(text1)\n",
        "    dfraw.at[i , \"isOffensiveText1\" ] =   isOffensiveTextans\n",
        "    \n",
        "    text2 =  dfraw['OCR'][i] \n",
        "    text2 = str(text2)\n",
        "    isOffensiveText2ans, isOffensiveText2ans0, isOffensiveText2ans1 = isOffensiveText1(text2)\n",
        "    dfraw.at[i , \"isOffensiveText2\" ] =   isOffensiveText2ans  \n",
        "\n",
        "    dfraw.at[i , \"isOffensiveText1softm0\" ] =   round (isOffensiveTextans0, 1)\n",
        "    dfraw.at[i , \"isOffensiveText1softm1\" ] =   round (isOffensiveTextans1, 1)\n",
        "    dfraw.at[i , \"isOffensiveText2softm0\" ] =   round (isOffensiveText2ans0  , 1)\n",
        "    dfraw.at[i , \"isOffensiveText2softm1\" ] =   round (isOffensiveText2ans1 , 1) \n",
        "\n"
      ],
      "metadata": {
        "id": "WbvrcHDOTSJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw"
      ],
      "metadata": {
        "id": "EYGB46e8YfeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "ZSclassifier = pipeline(\"zero-shot-classification\",  model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KnACcZWUalJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zQ0eamJxnd1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sG_hgX1ZrmU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sequence_to_classify = \"one day I will see the world\"\n",
        "#predictedclasses = ZSclassifier(sequence_to_classify, ZEROSHOTcandidate_labels, multi_class=True)\n",
        "#predictedclasses "
      ],
      "metadata": {
        "id": "HuvxMb_qmY1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOKERASlistofcolumnNames = [ \"CAT.isOffensiveText1\", \"NUM.isOffensiveText1softm0\", \"NUM.isOffensiveText1softm1\"]\n",
        "AUTOKERAScolumn_types = { 'CAT.isOffensiveText1': 'categorical'  , \n",
        "                         'NUM.isOffensiveText1softm0': 'numerical',\n",
        "                         'NUM.isOffensiveText1softm1': 'numerical'}"
      ],
      "metadata": {
        "id": "ARC5eOSf05bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (len(ZEROSHOTcandidate_labels)):\n",
        "  print(ZEROSHOTcandidate_labels[i])\n",
        "  AUTOKERASlistofcolumnNames.append('NUM.' + ZEROSHOTcandidate_labels[i])\n",
        "  AUTOKERAScolumn_types[ 'NUM.' + ZEROSHOTcandidate_labels[i] ] = \"numerical\"\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "6D7CSlfK06c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOKERASlistofcolumnNames"
      ],
      "metadata": {
        "id": "wAdSdcQpLQ-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOKERAScolumn_types"
      ],
      "metadata": {
        "id": "dsGYNVGrLTkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range( countofRecordstoProcess ):  \n",
        "  text1 =  dfraw['sentence'][i] \n",
        "  sequence_to_classify = str(text1)\n",
        "  predictedclasses = ZSclassifier(sequence_to_classify, ZEROSHOTcandidate_labels, multi_label=True)\n",
        "  for p in range(len(predictedclasses['labels'])):\n",
        "    aZSlabel = 'NUM.' + predictedclasses['labels'][p]\n",
        "    dfraw.at[i , aZSlabel ] =   round ( predictedclasses['scores'][p] , 3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pS4M9wjiqlXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw"
      ],
      "metadata": {
        "id": "Rs8qBuMwiHSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range( countofRecordstoProcess ):  \n",
        "  image1 = Image.open( dfraw['image_name'][i]  )\n",
        "  image_to_reason = image1.convert('RGB')\n",
        "  for p in range( len(VISUALREASONING_FactorsALL_ColomnName) ):\n",
        "    isVisualAnsCAT, isVisualAns0NUM, isVisualAns1NUM  = understnadImage1(image_to_reason, VISUALREASONING_FactorsALL_Reasoning[p])\n",
        "    dfraw.at[i , 'CAT.'+VISUALREASONING_FactorsALL_ColomnName[p] ] =  round( isVisualAnsCAT)\n",
        "    dfraw.at[i , 'NUM.'+VISUALREASONING_FactorsALL_ColomnName[p] + '0' ] =  round( isVisualAns0NUM, 3)\n",
        "    dfraw.at[i , 'NUM.'+VISUALREASONING_FactorsALL_ColomnName[p] + '1'] =  round( isVisualAns1NUM, 3)"
      ],
      "metadata": {
        "id": "krU6QQ6dd6Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  image1 = Image.open( dfraw['image_name'][i]  )\n",
        "  image1 = image1.convert('RGB')\n",
        "  isclipart, isclipart0, isclipart1  = understnadImage1(image1, \"The image is a clipart.\")\n"
      ],
      "metadata": {
        "id": "8s1x3nfgeJkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(len (VISUALREASONING_FactorsALL_ColomnName)):\n",
        "  print( str(i) + \". \" + VISUALREASONING_FactorsALL_ColomnName[i] + \"   ---------------------      \"   + VISUALREASONING_FactorsALL_Reasoning[i])"
      ],
      "metadata": {
        "id": "pDMStgCkd4wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw"
      ],
      "metadata": {
        "id": "wNjyshSxuSi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw.to_csv('processed2.csv')\n"
      ],
      "metadata": {
        "id": "GiESqQKvIjx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = drive.CreateFile()\n",
        "file1.SetContentFile('processed.csv')\n",
        "file1.Upload()"
      ],
      "metadata": {
        "id": "xz580ItFSlEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "RonXg2bOSNum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EALPmLeWSksU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_path = 'processed2.csv'\n",
        "\n",
        "dfNew = pd.read_csv(train_file_path)\n",
        "\n",
        "del dfNew['Unnamed: 0']\n",
        "del dfNew['image_name']\n",
        "del dfNew['sentence']\n",
        "del dfNew['DATASET']\n",
        "del dfNew['OCR']\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "WxW1UNGGgCRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IeWXjVWrC79u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PeL16ym8jMM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras\n"
      ],
      "metadata": {
        "id": "eN8CyfZeg4Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autokeras as ak\n"
      ],
      "metadata": {
        "id": "AsVfjmS8g6w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfNew"
      ],
      "metadata": {
        "id": "I2AvTVBYi_v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = dfNew\n",
        "print(type(x_train))  # pandas.DataFrame\n",
        "y_train = x_train.pop(\"label\")\n",
        "print(type(y_train))  # pandas.Series"
      ],
      "metadata": {
        "id": "5OTRqHYli-Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "EqJ4rFva_XJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "vIQf0hO__mOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOKERASlistofcolumnNames"
      ],
      "metadata": {
        "id": "GZs6rtdwC2jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOKERAScolumn_types"
      ],
      "metadata": {
        "id": "wjIhfi3UDtT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the structured data classifier.\n",
        "clf = ak.StructuredDataClassifier(\n",
        "    column_names= AUTOKERASlistofcolumnNames ,\n",
        "    column_types= AUTOKERAScolumn_types  ,\n",
        "    max_trials=10,  # It tries 10 different models.\n",
        "    overwrite=True,\n",
        ")"
      ],
      "metadata": {
        "id": "c0hJTN3I_RqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed the tensorflow Dataset to the classifier.\n",
        " \n",
        "clf.fit(x_train, y_train, epochs=20)\n"
      ],
      "metadata": {
        "id": "C3OG0kA8kTcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the structured data classifier.\n",
        "clf = ak.StructuredDataClassifier(\n",
        "    column_names=listofcolumnNames,\n",
        "    column_types={\"isclipart\": \"categorical\", \n",
        "                  \"isImageobscene\": \"categorical\",\n",
        "                  \"isImageExtremelyOffensive\": \"categorical\",  \n",
        "                  \"isImageOffensive\": \"categorical\",                  \n",
        "                  \"isOffensiveText1\": \"categorical\",                  \n",
        "                  \"isOffensiveText2\": \"categorical\" ,\n",
        "                  \"isclipart0\": \"numerical\",   \n",
        "                  \"isclipart1\": \"numerical\",   \n",
        "                  \"isImageobscene0\": \"numerical\",                               \n",
        "                  \"isImageobscene1\": \"numerical\",                               \n",
        "                  \"isImageExtremelyOffensive0\": \"numerical\",                               \n",
        "                  \"isImageExtremelyOffensive1\": \"numerical\",                               \n",
        "                  \"isImageOffensive0\": \"numerical\",                               \n",
        "                  \"isImageOffensive1\": \"numerical\",                               \n",
        "                  \"isOffensiveText1softm0\": \"numerical\",                               \n",
        "                  \"isOffensiveText1softm1\": \"numerical\",                               \n",
        "                  \"isOffensiveText2softm0\": \"numerical\",                               \n",
        "                  \"isOffensiveText2softm1\": \"numerical\"  \n",
        "                  },\n",
        "    max_trials=10,  # It tries 10 different models.\n",
        "    overwrite=True,\n",
        ")"
      ],
      "metadata": {
        "id": "FJ1mbjXbAgjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "MI8mpfD2gomD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "sMEAkEfBgqfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "listofcolumnNames = list(x_train.columns.values)\n",
        "listofcolumnNames"
      ],
      "metadata": {
        "id": "rPzHIIMjidAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the structured data classifier.\n",
        "clf = ak.StructuredDataClassifier(\n",
        "    column_names=listofcolumnNames,\n",
        "    column_types={\"isclipart\": \"categorical\", \n",
        "                  \"isImageobscene\": \"categorical\",\n",
        "                  \"isImageExtremelyOffensive\": \"categorical\",  \n",
        "                  \"isImageOffensive\": \"categorical\",                  \n",
        "                  \"isOffensiveText1\": \"categorical\",                  \n",
        "                  \"isOffensiveText2\": \"categorical\" ,\n",
        "                  \"isclipart0\": \"numerical\",   \n",
        "                  \"isclipart1\": \"numerical\",   \n",
        "                  \"isImageobscene0\": \"numerical\",                               \n",
        "                  \"isImageobscene1\": \"numerical\",                               \n",
        "                  \"isImageExtremelyOffensive0\": \"numerical\",                               \n",
        "                  \"isImageExtremelyOffensive1\": \"numerical\",                               \n",
        "                  \"isImageOffensive0\": \"numerical\",                               \n",
        "                  \"isImageOffensive1\": \"numerical\",                               \n",
        "                  \"isOffensiveText1softm0\": \"numerical\",                               \n",
        "                  \"isOffensiveText1softm1\": \"numerical\",                               \n",
        "                  \"isOffensiveText2softm0\": \"numerical\",                               \n",
        "                  \"isOffensiveText2softm1\": \"numerical\"  \n",
        "                  },\n",
        "    max_trials=10,  # It tries 10 different models.\n",
        "    overwrite=True,\n",
        ")"
      ],
      "metadata": {
        "id": "AWi7CG8TiV5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export as a Keras Model.\n",
        "bestmodel = clf.export_model()"
      ],
      "metadata": {
        "id": "gcKeG7RNlkTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    bestmodel.save(\"model_autokeras\", save_format=\"tf\")\n",
        "except Exception:\n",
        "    bestmodel.save(\"model_autokeras.h5\")"
      ],
      "metadata": {
        "id": "UpG-dgAklo1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(x_test)\n",
        "\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))"
      ],
      "metadata": {
        "id": "flOkcZx3htjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('processed.csv')"
      ],
      "metadata": {
        "id": "819G0g8oSPyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It tries 10 different models.\n",
        "clf = ak.StructuredDataClassifier(overwrite=True, max_trials=3)\n",
        "# Feed the structured data classifier with training data.\n",
        "clf.fit(x_train, y_train, epochs=10)\n"
      ],
      "metadata": {
        "id": "axHuk88dgVVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssfsfs"
      ],
      "metadata": {
        "id": "-epSUL6VbuVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare inputs\n",
        "encoding = processor([image1, image1], text, return_tensors=\"pt\")\n",
        "# forward pass\n",
        "outputs = model(input_ids=encoding.input_ids, pixel_values=encoding.pixel_values.unsqueeze(0))\n",
        "logits = outputs.logits\n",
        "idx = logits.argmax(-1).item()\n",
        "print(\"Predicted answer:\", model.config.id2label[idx]),"
      ],
      "metadata": {
        "id": "P0wjgemULUQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx"
      ],
      "metadata": {
        "id": "6lu6w9X6YQ3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "id": "z2luo6H1STvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "id": "nxkVTMMzSjAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "id": "Q7wIS5tETCYL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}